{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "from framework.feature_factory.helpers import Helpers\n",
    "from channelDemoMarket import Store\n",
    "\n",
    "spark = SparkSession.builder.appName('Test').getOrCreate()\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 96*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Istantiate store\n",
    "store = Store(_snapshot_date = \"2018-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get The feature factory\n",
    "ff = store.ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab some sales features\n",
    "mult_features, base_features = store.Sales().get_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For fisualization only.\n",
    "# Build a base dataframe from cores/sources\n",
    "example_df = store.get_core(\"issuer\")\n",
    "print(\"n_rows: %d\" %example_df.count())\n",
    "print(\"n_cols: %d\" %len(example_df.columns))\n",
    "example_df.show(truncate=True, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For visualization only.\n",
    "# Build a base dataframe from cores/sources\n",
    "bank_df = store.get_core(\"bank_id\").alias('bank')\n",
    "print(\"n_rows: %d\" %bank_df.count())\n",
    "print(\"n_cols: %d\" %len(bank_df.columns))\n",
    "bank_df.show(truncate=True, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a base dataframe from cores/sources\n",
    "store_sales_df = store.get_core(\"issuer\").filter(col('purchase_txn_amt') > 0).alias('clean_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"n_rows: %d\" %store_sales_df.count())\n",
    "print(\"n_cols: %d\" %len(store_sales_df.columns))\n",
    "store_sales_df.show(truncate=True, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue with example\n",
    "\n",
    "Make a join!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = store_sales_df.join(bank_df, ['issuer_name'])\\\n",
    "  .select('clean_amount.*', 'bank.issuer_id')\n",
    "base_df.show(truncate=True, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show distinct categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.select(\"chip_indicator_uid\").distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.select(\"product_uid\").distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Features Dataframe\n",
    "\n",
    "Here, we are simply calling the aggregation methods in mult_features to be applied over a group by on 'issuer_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = ff.append_features(base_df, groupBy_cols = ['issuer_name'], feature_sets=[mult_features])\n",
    "#feature_df = ff.append_features(store_sales_df, groupBy_cols = ['issuer_name'], feature_sets=[mult_features])\n",
    "feature_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Multipliers\n",
    "\n",
    "We will create a new features dataframe using composite aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.config.get_config('time_helpers').configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_multipliers = store.get_daterange_multiplier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_by_time_features = mult_features.multiply(time_multipliers, \"STORE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested features\n",
    "Now let's assume we have several cateogical columns for which we want to calculate aggregates.\n",
    "\n",
    "The categorical multiplier allows you to either specific to which columns you wish to apply the multiplier as well as a minimum distinct values count n and an ignore list of columns and it will efficiently find all the columns with < n distinct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_multiplier = Helpers().get_categoricals_multiplier(df = store.get_core(\"issuer\"),\n",
    "                                                               col_list = ['product_uid'])\n",
    "\n",
    "by_time_by_cat = mult_by_time_features.multiply(categorical_multiplier, \"STORE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = ff.append_features(base_df,\n",
    "                                groupBy_cols=['issuer_name'],\n",
    "                                feature_sets=[mult_features, mult_by_time_features, by_time_by_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"n cols = %d\" %len(feature_df.columns))\n",
    "feature_df.show(truncate=True, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further nesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_multiplier_2 = Helpers().get_categoricals_multiplier(df = store.get_core(\"issuer\"),\n",
    "                                                               col_list = ['chip_indicator_uid'])\n",
    "\n",
    "by_time_by_cat_by_cat = by_time_by_cat.multiply(categorical_multiplier_2, \"STORE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = ff.append_features(base_df,\n",
    "                                groupBy_cols=['issuer_name'],\n",
    "                                feature_sets=[by_time_by_cat_by_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"n cols = %d\" %len(feature_df.columns))\n",
    "feature_df.show(truncate=True, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
